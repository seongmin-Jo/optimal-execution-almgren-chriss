{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the default financial and AC Model parameters\n",
    "financial_params, ac_params = utils.get_env_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Financial Parameters</caption>\n",
       "<tr>\n",
       "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Almgren and Chriss Model Parameters</caption>\n",
       "<tr>\n",
       "  <th>Total Number of Shares to Sell:</th>                  <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th> <td>$0.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion:</th>           <td>1e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>       <td>2.5e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Days to Sell All the Shares:</th>               <td>5</td>     <th>  Single Step Variance:</th>             <td>0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Number of Trades:</th>                                    <td>5</td>     <th>  Time Interval between trades:</th>      <td>1.0</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "In the code below we use DDPG to find a policy that can generate optimal trading trajectories that minimize implementation shortfall, and can be benchmarked against the Almgren and Chriss model. We will implement a typical reinforcement learning workflow to train the actor and critic using the simulation environment. We feed the states observed from our simulator to an agent. The Agent first predicts an action using the actor model and performs the action in the environment. Then, environment returns the reward and new state. This process continues for the given number of episodes. To get accurate results, you should run the code at least 10,000 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseongmin/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [100/10000]\tAverage Shortfall: $2,276,855.50\n",
      "Episode [200/10000]\tAverage Shortfall: $2,562,256.53\n",
      "Episode [300/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [400/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [500/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [600/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [700/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [800/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [900/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1000/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1100/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1200/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1300/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1400/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1500/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1600/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1700/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1800/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [1900/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [2000/10000]\tAverage Shortfall: $2,562,500.00\n",
      "Episode [2100/10000]\tAverage Shortfall: $2,274,898.48\n",
      "Episode [2200/10000]\tAverage Shortfall: $723,277.88\n",
      "Episode [2300/10000]\tAverage Shortfall: $674,161.04\n",
      "Episode [2400/10000]\tAverage Shortfall: $671,785.43\n",
      "Episode [2500/10000]\tAverage Shortfall: $591,557.90\n",
      "Episode [2600/10000]\tAverage Shortfall: $701,206.83\n",
      "Episode [2700/10000]\tAverage Shortfall: $663,251.46\n",
      "Episode [2800/10000]\tAverage Shortfall: $655,084.07\n",
      "Episode [2900/10000]\tAverage Shortfall: $659,449.09\n",
      "Episode [3000/10000]\tAverage Shortfall: $646,931.59\n",
      "Episode [3100/10000]\tAverage Shortfall: $639,258.04\n",
      "Episode [3200/10000]\tAverage Shortfall: $650,964.71\n",
      "Episode [3300/10000]\tAverage Shortfall: $694,929.14\n",
      "Episode [3400/10000]\tAverage Shortfall: $721,996.06\n",
      "Episode [3500/10000]\tAverage Shortfall: $623,097.09\n",
      "Episode [3600/10000]\tAverage Shortfall: $663,362.56\n",
      "Episode [3700/10000]\tAverage Shortfall: $636,830.82\n",
      "Episode [3800/10000]\tAverage Shortfall: $584,683.50\n",
      "Episode [3900/10000]\tAverage Shortfall: $616,708.85\n",
      "Episode [4000/10000]\tAverage Shortfall: $616,084.22\n",
      "Episode [4100/10000]\tAverage Shortfall: $718,866.00\n",
      "Episode [4200/10000]\tAverage Shortfall: $684,810.78\n",
      "Episode [4300/10000]\tAverage Shortfall: $646,928.94\n",
      "Episode [4400/10000]\tAverage Shortfall: $679,275.21\n",
      "Episode [4500/10000]\tAverage Shortfall: $684,376.99\n",
      "Episode [4600/10000]\tAverage Shortfall: $681,756.27\n",
      "Episode [4700/10000]\tAverage Shortfall: $658,385.36\n",
      "Episode [4800/10000]\tAverage Shortfall: $707,782.24\n",
      "Episode [4900/10000]\tAverage Shortfall: $696,489.61\n",
      "Episode [5000/10000]\tAverage Shortfall: $546,455.98\n",
      "Episode [5100/10000]\tAverage Shortfall: $623,212.42\n",
      "Episode [5200/10000]\tAverage Shortfall: $656,851.99\n",
      "Episode [5300/10000]\tAverage Shortfall: $643,534.26\n",
      "Episode [5400/10000]\tAverage Shortfall: $647,717.51\n",
      "Episode [5500/10000]\tAverage Shortfall: $686,700.99\n",
      "Episode [5600/10000]\tAverage Shortfall: $635,667.43\n",
      "Episode [5700/10000]\tAverage Shortfall: $710,394.60\n",
      "Episode [5800/10000]\tAverage Shortfall: $714,161.10\n",
      "Episode [5900/10000]\tAverage Shortfall: $690,176.87\n",
      "Episode [6000/10000]\tAverage Shortfall: $650,223.44\n",
      "Episode [6100/10000]\tAverage Shortfall: $648,702.17\n",
      "Episode [6200/10000]\tAverage Shortfall: $654,725.73\n",
      "Episode [6300/10000]\tAverage Shortfall: $595,338.70\n",
      "Episode [6400/10000]\tAverage Shortfall: $641,657.88\n",
      "Episode [6500/10000]\tAverage Shortfall: $703,949.93\n",
      "Episode [6600/10000]\tAverage Shortfall: $624,754.87\n",
      "Episode [6700/10000]\tAverage Shortfall: $767,447.03\n",
      "Episode [6800/10000]\tAverage Shortfall: $667,982.41\n",
      "Episode [6900/10000]\tAverage Shortfall: $669,869.18\n",
      "Episode [7000/10000]\tAverage Shortfall: $643,812.85\n",
      "Episode [7100/10000]\tAverage Shortfall: $668,425.11\n",
      "Episode [7200/10000]\tAverage Shortfall: $622,542.38\n",
      "Episode [7300/10000]\tAverage Shortfall: $677,416.48\n",
      "Episode [7400/10000]\tAverage Shortfall: $714,595.93\n",
      "Episode [7500/10000]\tAverage Shortfall: $680,742.36\n",
      "Episode [7600/10000]\tAverage Shortfall: $657,446.71\n",
      "Episode [7700/10000]\tAverage Shortfall: $659,525.88\n",
      "Episode [7800/10000]\tAverage Shortfall: $651,421.05\n",
      "Episode [7900/10000]\tAverage Shortfall: $703,585.18\n",
      "Episode [8000/10000]\tAverage Shortfall: $732,664.15\n",
      "Episode [8100/10000]\tAverage Shortfall: $604,944.51\n",
      "Episode [8200/10000]\tAverage Shortfall: $719,089.48\n",
      "Episode [8300/10000]\tAverage Shortfall: $691,526.02\n",
      "Episode [8400/10000]\tAverage Shortfall: $640,348.00\n",
      "Episode [8500/10000]\tAverage Shortfall: $666,978.13\n",
      "Episode [8600/10000]\tAverage Shortfall: $714,817.27\n",
      "Episode [8700/10000]\tAverage Shortfall: $691,849.22\n",
      "Episode [8800/10000]\tAverage Shortfall: $698,076.56\n",
      "Episode [8900/10000]\tAverage Shortfall: $685,950.16\n",
      "Episode [9000/10000]\tAverage Shortfall: $668,019.90\n",
      "Episode [9100/10000]\tAverage Shortfall: $619,221.32\n",
      "Episode [9200/10000]\tAverage Shortfall: $731,831.23\n",
      "Episode [9300/10000]\tAverage Shortfall: $672,289.73\n",
      "Episode [9400/10000]\tAverage Shortfall: $638,035.40\n",
      "Episode [9500/10000]\tAverage Shortfall: $699,961.13\n",
      "Episode [9600/10000]\tAverage Shortfall: $699,942.48\n",
      "Episode [9700/10000]\tAverage Shortfall: $664,630.30\n",
      "Episode [9800/10000]\tAverage Shortfall: $671,260.14\n",
      "Episode [9900/10000]\tAverage Shortfall: $645,723.11\n",
      "Episode [10000/10000]\tAverage Shortfall: $624,622.94\n",
      "\n",
      "Average Implementation Shortfall: $1,058,731.22 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import syntheticChrissAlmgren as sca\n",
    "from ddpg_agent import Agent\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# Create simulation environment\n",
    "env = sca.MarketEnvironment()\n",
    "\n",
    "# Initialize Feed-forward DNNs for Actor and Critic models. \n",
    "agent = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(), random_seed=0)\n",
    "\n",
    "# Set the liquidation time\n",
    "lqt = 60\n",
    "\n",
    "# Set the number of trades\n",
    "n_trades = 60\n",
    "\n",
    "# Set trader's risk aversion\n",
    "tr = 1e-6\n",
    "\n",
    "# Set the number of episodes to run the simulation\n",
    "episodes = 10000\n",
    "\n",
    "shortfall_hist = np.array([])\n",
    "shortfall_deque = deque(maxlen=100)\n",
    "\n",
    "for episode in range(episodes): \n",
    "    # Reset the enviroment\n",
    "    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb = tr)\n",
    "\n",
    "    # set the environment to make transactions\n",
    "    env.start_transactions()\n",
    "\n",
    "    for i in range(n_trades + 1):\n",
    "      \n",
    "        # Predict the best action for the current state. \n",
    "        action = agent.act(cur_state, add_noise = True)\n",
    "        \n",
    "        # Action is performed and new state, reward, info are received. \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # current state, action, reward, new state are stored in the experience replay\n",
    "        agent.step(cur_state, action, reward, new_state, done)\n",
    "        \n",
    "        # roll over new state\n",
    "        cur_state = new_state\n",
    "\n",
    "        if info.done:\n",
    "            shortfall_hist = np.append(shortfall_hist, info.implementation_shortfall)\n",
    "            shortfall_deque.append(info.implementation_shortfall)\n",
    "            break\n",
    "        \n",
    "    if (episode + 1) % 100 == 0: # print average shortfall over last 100 episodes\n",
    "        print('\\rEpisode [{}/{}]\\tAverage Shortfall: ${:,.2f}'.format(episode + 1, episodes, np.mean(shortfall_deque)))        \n",
    "\n",
    "print('\\nAverage Implementation Shortfall: ${:,.2f} \\n'.format(np.mean(shortfall_hist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "The above code should provide you with a starting framework for incorporating more complex dynamics into our model. Here are a few things you can try out:\n",
    "\n",
    "- Incorporate your own reward function in the simulation environmet to see if you can achieve a expected shortfall that is better (lower) than that produced by the Almgren and Chriss model.\n",
    "\n",
    "\n",
    "- Experiment rewarding the agent at every step and only giving a reward at the end.\n",
    "\n",
    "\n",
    "- Use more realistic price dynamics, such as geometric brownian motion (GBM). The equations used to model GBM can be found in section 3b of this [paper](https://ro.uow.edu.au/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=1705&context=aabfj)\n",
    "\n",
    "\n",
    "- Try different functions for the action. You can change the values of the actions produced by the agent by using different functions. You can choose your function depending on the interpretation you give to the action. For example, you could set the action to be a function of the trading rate.\n",
    "\n",
    "\n",
    "- Add more complex dynamics to the environment. Try incorporate trading fees, for example. This can be done by adding and extra term to the fixed cost of selling, $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
